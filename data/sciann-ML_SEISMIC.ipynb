{"cells":[{"cell_type":"markdown","metadata":{"id":"n8sxhGSx07i0"},"source":["Example Google Colab script used to reproduce one of the benchmark cases from\n","  *Poulet, T. & Behnoudfar, P., \"Physics-informed neural network reconciles Australian displacements and tectonic stresses\", Scientific Reports (2023)*\n","\n","Script deploys SciANN (https://www.sciann.com), based on SciANN-SolidMechanics.py from https://github.com/sciann/sciann-applications/tree/master/SciANN-SolidMechanics by Ehsan Haghighat.\n","\n","Please note that this software is provided as-is, and there is no guarantee of future updates or support. The developers of this software are not responsible for any misuse or improper use of the software."]},{"cell_type":"markdown","metadata":{"id":"RU__xORMc1Ck"},"source":[" Imports, using specific versions of Python and tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRaPfb5GbJ-D"},"outputs":[],"source":["!pip install tensorflow==2.11"]},{"cell_type":"markdown","metadata":{"id":"9bB_C1YseL53"},"source":["(Restart the runtime before continuing)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"u5frE3m9bF-i","executionInfo":{"status":"ok","timestamp":1701206602268,"user_tz":-480,"elapsed":3651,"user":{"displayName":"Thomas Poulet","userId":"06678641627206312825"}}},"outputs":[],"source":["# This script was tested with Python 3.10 and tensorflow 2.11\n","import sys\n","assert sys.version[0:4] == '3.10', \"Using wrong Python version {0}\".format(sys.version)\n","import tensorflow as tf\n","assert tf.__version__[0:4] == '2.11', \"Using wrong tensorflow version {0}\".format(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"ZucmZV8qdwTa"},"source":["Install sciann (https://www.sciann.com)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTxsJnJpck4X"},"outputs":[],"source":["try:\n","  import sciann\n","  print('SciANN available')\n","except ImportError:\n","  print('Installing SciANN...')\n","  !pip install sciann\n","  import sciann\n","# This script was tested with SciANN 0.7.0.1\n","print('Using SciANN version {0}'.format(sciann.__version__))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"p7QfziydesOz","executionInfo":{"status":"ok","timestamp":1701206648404,"user_tz":-480,"elapsed":412,"user":{"displayName":"Thomas Poulet","userId":"06678641627206312825"}}},"outputs":[],"source":["import argparse, csv, os, time, sys\n","import numpy as np\n","from numpy import linalg as LA\n","from numpy.linalg import norm\n","from sciann.utils.math import diff\n","from sciann import SciModel, Functional, Parameter\n","from sciann import Data, Tie\n","from sciann import Variable, Field\n","from sciann import atan2, pow, sqrt\n","import tensorflow as tf\n","from keras import backend as K\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_g_1NjQgGvS"},"outputs":[],"source":["pi = np.pi\n","\n","# Parameter values to compare with analytical solution\n","lmbd = 1.0\n","mu = 0.5\n","qload = 4.0\n","\n","# Geometry\n","XMIN, XMAX = 0.0, 1.0\n","YMIN, YMAX = 0.0, 1.0\n","\n","# SciANN parameters\n","parser = argparse.ArgumentParser()\n","parser.add_argument('-l', '--layers', help='Num layers and neurons (default 4 layers each 40 neurons [40, 40, 40, 40])', type=int, nargs='+', default=[40]*4)\n","parser.add_argument('-af', '--actf', help='Activation function (default tanh)', type=str, nargs=1, default=['tanh'])\n","parser.add_argument('-nx', '--numx', help='Num Node in X (default 20)', type=int, nargs=1, default=[20])\n","parser.add_argument('-ny', '--numy', help='Num Node in Y (default 20)', type=int, nargs=1, default=[20])\n","parser.add_argument('-bs', '--batchsize', help='Batch size for Adam optimizer (default 32)', type=int, nargs=1, default=[32])\n","parser.add_argument('-e', '--epochs', help='Maximum number of epochs (default 10000)', type=int, nargs=1, default=[10000])\n","parser.add_argument('-lr', '--learningrate', help='Initial learning rate (default 0.001)', type=float, nargs=1, default=[[0, 2000, 4000], [2e-3, 1e-3, 1e-4]])\n","parser.add_argument('-in', '--independent_networks', help='Use independent networks for each var (default False)', type=bool, nargs=1, default=[False])\n","parser.add_argument('-v', '--verbose', help='Show training progress (default 2) (check Keras.fit)', type=int, nargs=1, default=[2])\n","\n","parser.add_argument('--shuffle', help='Shuffle data for training (default True)', type=bool, nargs=1, default=[True])\n","parser.add_argument('--stopafter', help='Patience argument from Keras (default 500)', type=int, nargs=1, default=[500])\n","parser.add_argument('--savefreq', help='Frequency to save weights (each n-epoch)', type=int, nargs=1, default=[100000])\n","parser.add_argument('--dtype', help='Data type for weights and biases (default float64)', type=str, nargs=1, default=['float64'])\n","parser.add_argument('--gpu', help='Use GPU if available (default False)', type=bool, nargs=1, default=[False])\n","parser.add_argument('-op', '--outputpath', help='Output path (default ./file_name)', type=str, nargs=1, default=['output-benchmark'])\n","parser.add_argument('-of', '--outputprefix', help='Output path (default res**)', type=str, nargs=1, default=['res'])\n","\n","parser.add_argument('-nxp', '--numxplot', help='Num Node in X for ploting final results (default 200)', type=int, nargs=1, default=[200])\n","parser.add_argument('-nyp', '--numyplot', help='Num Node in Y for ploting final results (default 200)', type=int, nargs=1, default=[200])\n","parser.add_argument('--plot', help='Plot the model', nargs='?', default=False)\n","\n","parser.add_argument('--case', help='Benchmark case/scenario index (default 1)', type=int, nargs=1, default=[1])\n","\n","sys.argv=[''] # mimicking arguments in interactive session (Google Colab)\n","args = parser.parse_args()\n","if not args.gpu[0]:\n","  os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n","print('os.environ[\"CUDA_VISIBLE_DEVICES\"]={}'.format(os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n","\n","def bodyfx(xx):\n","  x, y = xx[0], xx[1]\n","  Q = qload\n","  frc = - lmbd*(4*pi**2*np.cos(2*pi*x)*np.sin(pi*y) - Q*y**3*pi*np.cos(pi*x)) \\\n","        - mu*(pi**2*np.cos(2*pi*x)*np.sin(pi*y) - Q*y**3*pi*np.cos(pi*x)) \\\n","        - 8*mu*pi**2*np.cos(2*pi*x)*np.sin(pi*y)\n","  return frc\n","\n","def bodyfy(xx):\n","  x, y = xx[0], xx[1]\n","  Q = qload\n","  frc = lmbd*(3*Q*y**2*np.sin(pi*x) - 2*pi**2*np.cos(pi*y)*np.sin(2*pi*x)) \\\n","        - mu*(2*pi**2*np.cos(pi*y)*np.sin(2*pi*x) + (Q*y**4*pi**2*np.sin(pi*x))/4) \\\n","        + 6*Q*mu*y**2*np.sin(pi*x)\n","  return frc\n","\n","def dispx(xx):\n","  x, y = xx[0], xx[1]\n","  return np.cos(2*pi*x) * np.sin(pi*y)\n","\n","def dispy(xx):\n","  x, y = xx[0], xx[1]\n","  Q = qload\n","  return np.sin(pi*x) * Q * y**4/4\n","\n","def strainxx(xx):\n","  x, y = xx[0], xx[1]\n","  Q = qload\n","  return -2*pi*np.sin(2*pi*x)*np.sin(pi*y)\n","\n","def strainyy(xx):\n","  x, y = xx[0], xx[1]\n","  Q = qload\n","  return np.sin(pi*x)*Q*y**3\n","\n","def strainxy(xx):\n","  x, y = xx[0], xx[1]\n","  Q = qload\n","  return 0.5*(pi*np.cos(2*pi*x)*np.cos(pi*y) + pi*np.cos(pi*x)*Q*y**4/4)\n","\n","def stressxx(xx):\n","  return (lmbd+2*mu)*strainxx(xx) + lmbd*strainyy(xx)\n","\n","def stressyy(xx):\n","  return (lmbd+2*mu)*strainyy(xx) + lmbd*strainxx(xx)\n","\n","def stressxy(xx):\n","  return 2.0*mu*strainxy(xx)\n","\n","def myStressOrientation(xx):\n","  ''' Observations regarding stress orientation (in radian)\n","      using analytical solution\n","  '''\n","  x, y = xx[0], xx[1]\n","  sxx = stressxx(xx).flatten()\n","  sxy = stressxy(xx).flatten()\n","  syy = stressyy(xx).flatten()\n","  tmp = np.stack([sxx, sxy, sxy, syy], axis=-1)\n","  n = sxx.shape[0]\n","  tmp = tmp.reshape(n, 2, 2)\n","  eigenvalues, eigenvectors = LA.eig(tmp)\n","  i_mins = np.argmin(eigenvalues, axis=-1)\n","  eigv1 = eigenvectors[np.arange(n), :, i_mins]\n","  angles = np.arctan2(eigv1[:,1], eigv1[:,0])\n","  az = getShortAngleDifference(angles, np.zeros_like(angles))\n","  az2 = az.reshape(-1, 1)\n","  return az2\n","\n","def cust_pcolor(AX, X, Y, C, title):\n","  im = AX.pcolor(X, Y, C, cmap=\"jet\")\n","  AX.axis(\"equal\")\n","  AX.axis(\"off\")\n","  if title:\n","    AX.set_title(title, fontsize=5, y=1., pad=2)\n","  colorbar = plt.colorbar(im, ax=AX, shrink=0.8)\n","  colorbar.ax.tick_params(labelsize=3)\n","  for tick in colorbar.ax.get_yticklabels(which='both'):\n","    tick.set_fontsize(5)\n","  for tick in colorbar.ax.get_xticklabels(which='both'):\n","    tick.set_fontsize(5)\n","\n","def cust_quiver(AX, X, Y, U, V, title):\n","  AX.axis(\"equal\")\n","  AX.axis(\"off\")\n","  im = AX.quiver(X, Y, U, V, angles='xy', scale_units='xy')\n","  AX.set_title(title, fontsize=5, y=1., pad=2)\n","\n","def cust_plot(AX, X, Y, title, xlabel, ylabel):\n","  im = AX.plot(X, Y)\n","  AX.set_title(title, fontsize=5)\n","  if xlabel is not None: AX.set_xlabel(xlabel, fontsize=5)\n","  if ylabel is not None: AX.set_ylabel(ylabel, fontsize=5)\n","  for tick in AX.get_yticklabels(which='both'):\n","    tick.set_fontsize(5)\n","  for tick in AX.get_xticklabels(which='both'):\n","    tick.set_fontsize(5)\n","\n","def cust_semilogx(AX, X, Y, xlabel, ylabel):\n","  im = []\n","  if X is None:\n","    im = AX.semilogy(Y, c='k', lw=1)\n","  else:\n","    im = AX.semilogy(X, Y, c='k', lw=1)\n","  if xlabel is not None: AX.set_xlabel(xlabel, fontsize=5)\n","  if ylabel is not None: AX.set_ylabel(ylabel, fontsize=5)\n","  for tick in AX.get_yticklabels(which='both'):\n","    tick.set_fontsize(5)\n","  for tick in AX.get_xticklabels(which='both'):\n","    tick.set_fontsize(5)\n","\n","def getShortAngleDifference(alpha, beta):\n","  ''' Compute short angle difference between 2 directions\n","      @param alpha[in] - np.array (float), angles in radian\n","      @param beta[in] - np.array (float), angles in radian\n","  '''\n","  return (((alpha-beta)%np.pi)+0.5*np.pi)%np.pi - 0.5*np.pi\n","\n","def mseOnShortAngle(y_true, y_pred):\n","  ''' Loss function with Mean Squared Error when inputs are angles and we want\n","    to compare the shortest angle differences modulo pi.\n","    y_true and y_pred are tensors.\n","  '''\n","  short_angle = tf.math.floormod(tf.math.floormod(y_true - y_pred, pi) + pi/2., pi) - pi/2.\n","  return K.mean(K.square(short_angle), axis=-1)\n","\n","def getFileName(args):\n","  ''' Get root file name for outputs and save files of training results '''\n","  out_rootfilename = os.path.join(args.outputpath[0],\n","    args.outputprefix[0] + \"_case{}\".format(args.case[0]))\n","  return out_rootfilename\n","\n","def train():\n","  ''' Train for specific benchmark case/scenario '''\n","  supported_cases = [1, 2, 3, 4, 5, 6, 7]\n","  assert args.case[0] in supported_cases, 'invalid case \"{0}\". Supported cases are {1}'\\\n","    .format(args.case[0], supported_cases)\n","\n","  # define output folder.\n","  if not os.path.isdir(args.outputpath[0]):\n","    os.mkdir(args.outputpath[0])\n","  fname = getFileName(args)\n","\n","  # Neural Network Setup.\n","  x = Variable(\"x\", dtype=args.dtype[0])\n","  y = Variable(\"y\", dtype=args.dtype[0])\n","\n","  if args.independent_networks[0]:\n","    Uxy = Functional(\"Uxy\", [x, y], args.layers, args.actf[0])\n","    Vxy = Functional(\"Vxy\", [x, y], args.layers, args.actf[0])\n","    Sxx = Functional(\"Sxx\", [x, y], args.layers, args.actf[0])\n","    Syy = Functional(\"Syy\", [x, y], args.layers, args.actf[0])\n","    Sxy = Functional(\"Sxy\", [x, y], args.layers, args.actf[0])\n","  else:\n","    Uxy, Vxy, Sxx, Syy, Sxy = Functional(\n","      [\"Uxy\", \"Vxy\", \"Sxx\", \"Syy\", \"Sxy\"],\n","      [x, y], args.layers, args.actf[0])\n","\n","  lame1 = lmbd\n","  lame2 = mu\n","\n","  C11 = (2*lame2 + lame1)\n","  C12 = lame1\n","  C33 = 2*lame2\n","\n","  Exx = diff(Uxy, x)\n","  Eyy = diff(Vxy, y)\n","  Exy = (diff(Uxy, y) + diff(Vxy, x))*0.5\n","\n","  # Define constraints\n","  d1 = Data(Uxy)\n","  d2 = Data(Vxy)\n","  d3, d4 = None, None\n","  if args.case[0] in [1, 2]:\n","    d3 = Data(Sxx)\n","    d4 = Data(Syy)\n","\n","  eigenval, az = None, None\n","  if args.case[0] in [2, 3, 4, 5, 6]:\n","    eigenval = 0.5 * ( Sxx + Syy - sqrt( pow(Sxx - Syy, 2) + 4 * pow(Sxy, 2) ) )\n","    az = Data( atan2(Sxy, eigenval - Syy) ) # stress orientation angle (azimuth)\n","\n","  c1 = Tie(Sxx, Exx*C11 + Eyy*C12)\n","  c2 = Tie(Syy, Eyy*C11 + Exx*C12)\n","  c3 = Tie(Sxy, Exy*C33)\n","\n","  Lx = diff(Sxx, x) + diff(Sxy, y)\n","  Ly = diff(Sxy, x) + diff(Syy, y)\n","\n","  # Define the optimization model (set of inputs and constraints) per case\n","  targets = [d1, d2]\n","  loss_funcs = [\"mse\", \"mse\"]\n","  if args.case[0] in [1, 2]:\n","    targets += [d3, d4] # add stress values targets\n","    loss_funcs += [\"mse\", \"mse\"]\n","  if args.case[0] in [2, 3, 4, 5, 6]:\n","    targets += [az] # add stress orientations targets\n","    loss_funcs += [mseOnShortAngle]\n","  targets += [c1, c2, c3, Lx, Ly]\n","  loss_funcs += [\"mse\", \"mse\", \"mse\", \"mse\", \"mse\"]\n","  model = SciModel(\n","    inputs=[x, y],\n","    targets=targets,\n","    loss_func=loss_funcs\n","  )\n","  with open(\"{}_summary\".format(fname), \"w\") as fobj:\n","    model.summary(print_fn=lambda x: fobj.write(x + '\\n'))\n","\n","  # Prepare training data\n","  ## Training grid\n","  Xmesh = np.linspace(XMIN, XMAX, args.numx[0]).reshape((-1, 1))\n","  Ymesh = np.linspace(YMIN, YMAX, args.numy[0]).reshape((-1, 1))\n","  X, Y = np.meshgrid(Xmesh, Ymesh)\n","\n","  input_data = [X.reshape(-1, 1), Y.reshape(-1, 1)]\n","\n","  # Get various boundary sets\n","  XTOL, YTOL = np.array([XMAX-XMIN, YMAX-YMIN])*1e-6\n","  left_ids = np.where(abs(input_data[0] - XMIN) < XTOL)[0]\n","  right_ids = np.where(abs(input_data[0] - XMAX) < XTOL)[0]\n","  bot_ids = np.where(abs(input_data[1] - YMIN) < YTOL)[0]\n","  top_ids = np.where(abs(input_data[1] - YMAX) < YTOL)[0]\n","  BC_ids_all = np.unique(np.concatenate([left_ids, right_ids, bot_ids, top_ids]))\n","  BC_ids_sid = np.unique(np.concatenate([left_ids, right_ids]))\n","  BC_ids_bot = np.unique(np.concatenate([bot_ids]))\n","  BC_ids_top = np.unique(np.concatenate([top_ids]))\n","  BC_ids_top_bot = np.unique(np.concatenate([top_ids, bot_ids]))\n","  BC_ids_bot_sides = np.unique(np.concatenate([bot_ids, left_ids, right_ids]))\n","  BC_ids_botpt1 = np.where(abs(input_data[0] - XMIN) + abs(input_data[1] - YMIN)  < XTOL)[0]\n","  BC_ids_botpt2 = np.where(abs(input_data[0] - XMAX) + abs(input_data[1] - YMIN)  < XTOL)[0]\n","  BC_ids_toppt2 = np.where(abs(input_data[0] - XMAX) + abs(input_data[1] - YMAX)  < XTOL)[0]\n","  BC_ids_botcorners = np.unique(np.concatenate([BC_ids_botpt1, BC_ids_botpt2]))\n","  BC_ids_oppcorners = np.unique(np.concatenate([BC_ids_botpt1, BC_ids_toppt2]))\n","\n","  ## data associated to constrains defined earlier\n","  # Define constraints\n","  data_d1 = dispx(input_data) # Dirichlet BC in u_x\n","  data_d2 = dispy(input_data) # Dirichlet BC in u_y\n","  data_d3, data_d4 = None, None\n","  if args.case[0] in [1, 2]:\n","    data_d3 = stressxx(input_data)\n","    data_d4 = stressyy(input_data)\n","  data_az = None\n","  if args.case[0] in [2, 3, 4, 5, 6]:\n","    data_az = myStressOrientation(input_data) # stress orientation data\n","  data_c1 = 'zeros'\n","  data_c2 = 'zeros'\n","  data_c3 = 'zeros'\n","  data_Lx = bodyfx(input_data)\n","  data_Ly = bodyfy(input_data)\n","\n","  BC_ids_disp_x, BC_ids_disp_y = None, None\n","  if args.case[0] in [1, 2, 3]:\n","    BC_ids_disp_x = BC_ids_top_bot\n","    BC_ids_disp_y = BC_ids_bot_sides\n","  elif args.case[0] in [4]:\n","    BC_ids_disp_x = BC_ids_bot\n","    BC_ids_disp_y = BC_ids_bot\n","  elif args.case[0] in [5]:\n","    BC_ids_disp_x = BC_ids_botcorners\n","    BC_ids_disp_y = BC_ids_botcorners\n","  elif args.case[0] in [6, 7]:\n","    BC_ids_disp_x = BC_ids_oppcorners\n","    BC_ids_disp_y = BC_ids_oppcorners\n","\n","  target_data = [(BC_ids_disp_x, data_d1), # disp_x at some boundaries\n","                 (BC_ids_disp_y, data_d2)] # disp_y at some boundaries\n","  if args.case[0] in [1, 2]:\n","    target_data += [(BC_ids_sid, data_d3), # Sxx at some boundaries\n","                    (BC_ids_top, data_d4)] # Syy at some boundaries\n","  if args.case[0] in [2, 3, 4, 5, 6]:\n","    target_data += [data_az] # stress orientation at all test points\n","  target_data += [data_c1, data_c2, data_c3, # constitutive model at all test points\n","                  data_Lx, data_Ly] # body force at all test points\n","\n","  # Train the model\n","  training_time = time.time()\n","  history = model.train(\n","    x_true=input_data,\n","    y_true=target_data,\n","    epochs=args.epochs[0],\n","    batch_size=args.batchsize[0],\n","    shuffle=args.shuffle[0],\n","    learning_rate=args.learningrate,\n","    stop_after=args.stopafter[0],\n","    verbose=args.verbose[0],\n","  )\n","  training_time = time.time() - training_time\n","\n","  for loss in history.history:\n","    np.savetxt(fname+\"_{}\".format(\"_\".join(loss.split(\"/\"))),\n","                np.array(history.history[loss]).reshape(-1, 1))\n","\n","  time_steps = np.linspace(0, training_time, len(history.history[\"loss\"]))\n","  np.savetxt(fname+\"_Time\", time_steps.reshape(-1,1))\n","\n","  # Post process the trained model.\n","  Xmesh_plot = np.linspace(XMIN, XMAX, args.numxplot[0]).reshape((-1, 1))\n","  Ymesh_plot = np.linspace(YMIN, YMAX, args.numyplot[0]).reshape((-1, 1))\n","  X_plot, Y_plot = np.meshgrid(Xmesh_plot, Ymesh_plot)\n","  input_plot = [X_plot.reshape(-1, 1), Y_plot.reshape(-1, 1)]\n","\n","  Uxy_pred = Uxy.eval(model, input_plot)\n","  Vxy_pred = Vxy.eval(model, input_plot)\n","  Exx_pred = Exx.eval(model, input_plot)\n","  Eyy_pred = Eyy.eval(model, input_plot)\n","  Exy_pred = Exy.eval(model, input_plot)\n","  Sxx_pred = Sxx.eval(model, input_plot)\n","  Syy_pred = Syy.eval(model, input_plot)\n","  Sxy_pred = Sxy.eval(model, input_plot)\n","\n","  np.savetxt(fname+\"_Xmesh\", X_plot, delimiter=', ')\n","  np.savetxt(fname+\"_Ymesh\", Y_plot, delimiter=', ')\n","  np.savetxt(fname+\"_Uxy\", Uxy_pred.reshape(X_plot.shape), delimiter=', ')\n","  np.savetxt(fname+\"_Vxy\", Vxy_pred.reshape(X_plot.shape), delimiter=', ')\n","  np.savetxt(fname+\"_Exx\", Exx_pred.reshape(X_plot.shape), delimiter=', ')\n","  np.savetxt(fname+\"_Eyy\", Eyy_pred.reshape(X_plot.shape), delimiter=', ')\n","  np.savetxt(fname+\"_Exy\", Exy_pred.reshape(X_plot.shape), delimiter=', ')\n","  np.savetxt(fname+\"_Sxx\", Sxx_pred.reshape(X_plot.shape), delimiter=', ')\n","  np.savetxt(fname+\"_Syy\", Syy_pred.reshape(X_plot.shape), delimiter=', ')\n","  np.savetxt(fname+\"_Sxy\", Sxy_pred.reshape(X_plot.shape), delimiter=', ')\n","\n","def plot(do_show=True):\n","  fname = getFileName(args)\n","\n","  ### Plot convergence\n","  loss = np.loadtxt(fname+\"_loss\")\n","  time = np.loadtxt(fname+\"_Time\")\n","  lr = np.loadtxt(fname+\"_lr\")\n","  fig, ax = plt.subplots(1, 2, figsize=(4, 2), dpi=300)\n","  cust_semilogx(ax[0], None, loss/loss[0], \"epochs\", \"L/L0\")\n","  cust_semilogx(ax[1], None, lr, \"epochs\", \"learning rate\")\n","  fig.subplots_adjust(left=0.1, right=0.97, bottom=0.15, top=0.9, wspace=0.6, hspace=0.2)\n","  plt.savefig(\"{}_loss.png\".format(fname))\n","\n","  Xmesh = np.loadtxt(fname+\"_Xmesh\", delimiter=',')\n","  Ymesh = np.loadtxt(fname+\"_Ymesh\", delimiter=',')\n","\n","  ### Plot results\n","  fig, ax = plt.subplots(3, 2, figsize=(2., 3.), dpi=300)\n","  Ux = np.loadtxt(fname+\"_Uxy\", delimiter=',')\n","  Uy = np.loadtxt(fname+\"_Vxy\", delimiter=',')\n","  Utotal = np.sqrt(Ux*Ux + Uy*Uy)\n","  Ux_ana = dispx([Xmesh, Ymesh]) # analytical solution\n","  Uy_ana = dispy([Xmesh, Ymesh]) # analytical solution\n","  Ux_err = Ux - Ux_ana\n","  Uy_err = Uy - Uy_ana\n","  L2_relerr_ux = norm(Ux_err, ord=2) / norm(Ux_ana, ord=2)\n","  L2_relerr_uy = norm(Uy_err, ord=2) / norm(Uy_ana, ord=2)\n","  Linf_err_ux = np.abs(Ux_err).max()\n","  Linf_err_uy = np.abs(Uy_err).max()\n","  print(\"The minimum relative loss is\", min(loss)/loss[0])\n","  print(\"The L_inf error on u_x is\", Linf_err_ux)\n","  print(\"The L_inf error on u_y is\", Linf_err_uy)\n","  print(\"The L_2 relative error on u_x is\", L2_relerr_ux)\n","  print(\"The L_2 relative error on u_y is\", L2_relerr_uy)\n","  cust_pcolor(ax[0,0], Xmesh, Ymesh, Ux, \"Ux\")\n","  cust_pcolor(ax[0,1], Xmesh, Ymesh, Uy, \"Uy\")\n","  cust_pcolor(ax[1,0], Xmesh, Ymesh, Ux_err, \"Ux error\")\n","  cust_pcolor(ax[1,1], Xmesh, Ymesh, Uy_err, \"Uy error\")\n","  cust_pcolor(ax[2,0], Xmesh, Ymesh, myStressOrientation([Xmesh, Ymesh]).reshape(Xmesh.shape), \"data azimuth\")\n","  Sxx_pred = np.loadtxt(fname+\"_Sxx\", delimiter=',')\n","  Sxy_pred = np.loadtxt(fname+\"_Sxy\", delimiter=',')\n","  Syy_pred = np.loadtxt(fname+\"_Syy\", delimiter=',')\n","  eigenval_pred = 0.5 * ( Sxx_pred  + Syy_pred  - np.sqrt( np.square(Sxx_pred - Syy_pred) + 4 * np.square(Sxy_pred) ) )\n","  az_pred = np.arctan2(Sxy_pred , eigenval_pred - Syy_pred) # stress orientation angle (azimuth)\n","  az_pred2 = getShortAngleDifference(az_pred, np.zeros_like(az_pred))\n","  cust_pcolor(ax[2,1], Xmesh, Ymesh, az_pred2, \"Predicted azimuth\")\n","  plt.subplots_adjust(left=0.01, right=0.9, bottom=0.01, top=0.92, hspace=0.4)\n","  plt.savefig(\"{}_disp.png\".format(fname))\n","\n","  if do_show:\n","    plt.show()\n","\n","class Timer(object):\n","  def __init__(self, name=None):\n","    self.name = name\n","\n","  def __enter__(self):\n","    self.tstart = time.time()\n","\n","  def __exit__(self, type, value, traceback):\n","    if self.name:\n","      print('[%s]' % self.name,)\n","    print('Elapsed: %.2f s' % (time.time() - self.tstart))\n","\n","if args.plot==False:\n","  with Timer('Training'):\n","    train()\n","  from google.colab import output\n","  output.clear()\n","  plot(do_show=False)\n","else:\n","  plot(do_show=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CmjnbdNBPoN"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1kU1LHafhkUA4hoCMSR1Qvn2YPgZftLhI","timestamp":1701135114594}],"mount_file_id":"1kU1LHafhkUA4hoCMSR1Qvn2YPgZftLhI","authorship_tag":"ABX9TyPXsGwCoHOXa8dLhV3QdFNP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}